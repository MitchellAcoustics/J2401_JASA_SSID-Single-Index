<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
    <meta charset="utf-8">
    <meta name="generator" content="quarto-1.4.553">

    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

    <meta name="author" content="Andrew Mitchell">
    <meta name="author" content="Francesco Aletta">
    <meta name="author" content="Tin Oberman">
    <meta name="author" content="Jian Kang">
    <meta name="dcterms.date" content="2024-04-20">
    <meta name="keywords" content="keyword1, keyword2">

    <title>SPI - Defining bespoke and archetypal context-dependent Soundscape Perception Indices</title>
    <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      div.columns{display: flex; gap: min(4vw, 1.5em);}
      div.column{flex: auto; overflow-x: auto;}
      div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
      ul.task-list{list-style: none;}
      ul.task-list li input[type="checkbox"] {
        width: 0.8em;
        margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
        vertical-align: middle;
      }
      /* CSS for syntax highlighting */
      pre > code.sourceCode { white-space: pre; position: relative; }
      pre > code.sourceCode > span { line-height: 1.25; }
      pre > code.sourceCode > span:empty { height: 1.2em; }
      .sourceCode { overflow: visible; }
      code.sourceCode > span { color: inherit; text-decoration: inherit; }
      div.sourceCode { margin: 1em 0; }
      pre.sourceCode { margin: 0; }
      @media screen {
      div.sourceCode { overflow: auto; }
      }
      @media print {
      pre > code.sourceCode { white-space: pre-wrap; }
      pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
      }
      pre.numberSource code
        { counter-reset: source-line 0; }
      pre.numberSource code > span
        { position: relative; left: -4em; counter-increment: source-line; }
      pre.numberSource code > span > a:first-child::before
        { content: counter(source-line);
          position: relative; left: -1em; text-align: right; vertical-align: baseline;
          border: none; display: inline-block;
          -webkit-touch-callout: none; -webkit-user-select: none;
          -khtml-user-select: none; -moz-user-select: none;
          -ms-user-select: none; user-select: none;
          padding: 0 4px; width: 4em;
        }
      pre.numberSource { margin-left: 3em;  padding-left: 4px; }
      div.sourceCode
        {   }
      @media screen {
      pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
      }
    </style>

    <style>
      body.hypothesis-enabled #quarto-embed-header {
        padding-right: 36px;
      }

      #quarto-embed-header {
        height: 3em;
        width: 100%;
        display: flex;
        justify-content: space-between;
        align-items: center;
        border-bottom: solid 1px;
      }

      #quarto-embed-header h6 {
        font-size: 1.1em;
        padding-top: 0.6em;
        margin-left: 1em;
        margin-right: 1em;
        font-weight: 400;
      }

      #quarto-embed-header a.quarto-back-link,
      #quarto-embed-header a.quarto-download-embed {
        font-size: 0.8em;
        margin-top: 1em;
        margin-bottom: 1em;
        margin-left: 1em;
        margin-right: 1em;
      }

      .quarto-back-container {
        padding-left: 0.5em;
        display: flex;
      }

      .headroom {
          will-change: transform;
          transition: transform 200ms linear;
      }

      .headroom--pinned {
          transform: translateY(0%);
      }

      .headroom--unpinned {
          transform: translateY(-100%);
      }      
    </style>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script>
    window.document.addEventListener("DOMContentLoaded", function () {

      var header = window.document.querySelector("#quarto-embed-header");
      const titleBannerEl = window.document.querySelector("body > #title-block-header");
      if (titleBannerEl) {
        titleBannerEl.style.paddingTop = header.clientHeight + "px";
      }
      const contentEl = window.document.getElementById('quarto-content');
      for (const child of contentEl.children) {
        child.style.paddingTop = header.clientHeight + "px";
        child.style.marginTop = "1em";
      }

      // Use the article root if the `back` call doesn't work. This isn't perfect
      // but should typically work
      window.quartoBackToArticle = () => {
        var currentUrl = window.location.href;
        window.history.back();
        setTimeout(() => {
            // if location was not changed in 100 ms, then there is no history back
            if(currentUrl === window.location.href){              
                // redirect to site root
                window.location.href = "../index.html";
            }
        }, 100);
      }

      const headroom = new window.Headroom(header, {
        tolerance: 5,
        onPin: function () {
        },
        onUnpin: function () {
        },
      });
      headroom.init();
    });
    </script>

    
<script src="../site_libs/manuscript-notebook/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
     <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>   <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script> 
      </head>

  <body class="quarto-notebook">
    <div id="quarto-embed-header" class="headroom fixed-top bg-primary">
      
      <a onclick="window.quartoBackToArticle(); return false;" class="btn btn-primary quarto-back-link" href=""><i class="bi bi-caret-left"></i> Back to Article</a>
      <h6><i class="bi bi-journal-code"></i> SPI - Defining bespoke and archetypal context-dependent Soundscape Perception Indices</h6>

            <a href="../notebooks/draft1.ipynb" class="btn btn-primary quarto-download-embed" download="draft1.ipynb">Download Notebook</a>
          </div>

     <header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">SPI - Defining bespoke and archetypal context-dependent Soundscape Perception Indices</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Andrew Mitchell <a href="mailto:andrew.mitchell.18@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University College London
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Francesco Aletta <a href="mailto:f.aletta@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University College London
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Tin Oberman <a href="mailto:t.oberman@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        University College London
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Jian Kang <a href="mailto:j.kang@ucl.ac.uk" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">April 20, 2024</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      </div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>The soundscape approach provides a basis for considering the holistic perception of sound environments, in context. While steady advancements have been made in methods for assessment and analysis, a gap exists for comparing soundscapes and quantifying improvements in the multi-dimensional perception of a soundscape. To this end, there is a need for the creation of single value indices to compare soundscape quality which incorporate context, aural diversity, and specific design goals for a given application. Just as a variety of decibel-based indices have been developed for various purposes (e.g.&nbsp;LAeq, LCeq, L90, Lden, etc.), the soundscape approach requires the ability to create novel indices for different uses, but which share a common language and understanding. We therefore propose a unified framework for creating both bespoke and standardised single index measures of soundscape perception based on the soundscape circumplex model, allowing for new metrics to be defined in the future. The implementation of this framework is demonstrated through the creation of a public spaced typology-based index using data collected under the SSID Protocol, which was designed specifically for the purpose of defining soundscape indices. Indices developed under this framework can enable a broader and more efficient application of the soundscape approach.</p>
      </div>
    </div>

    <div>
      <div class="keywords">
        <div class="block-title">Keywords</div>
        <p>keyword1, keyword2</p>
      </div>
    </div>

    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#the-need-for-soundscape-indices" id="toc-the-need-for-soundscape-indices" class="nav-link" data-scroll-target="#the-need-for-soundscape-indices">The need for Soundscape Indices</a></li>
  <li><a href="#note-on-terminology" id="toc-note-on-terminology" class="nav-link" data-scroll-target="#note-on-terminology">Note on Terminology</a></li>
  <li><a href="#existing-soundscape-indices" id="toc-existing-soundscape-indices" class="nav-link" data-scroll-target="#existing-soundscape-indices">Existing ‘Soundscape Indices’</a>
  <ul class="collapse">
  <li><a href="#soundscape-ecology" id="toc-soundscape-ecology" class="nav-link" data-scroll-target="#soundscape-ecology">Soundscape Ecology</a></li>
  <li><a href="#soundscape-perception" id="toc-soundscape-perception" class="nav-link" data-scroll-target="#soundscape-perception">Soundscape Perception</a></li>
  </ul></li>
  <li><a href="#motivations-goals" id="toc-motivations-goals" class="nav-link" data-scroll-target="#motivations-goals">Motivations &amp; Goals</a></li>
  </ul></li>
  <li><a href="#theoretical-background-of-quantitative-soundscape-perception-measurements" id="toc-theoretical-background-of-quantitative-soundscape-perception-measurements" class="nav-link" data-scroll-target="#theoretical-background-of-quantitative-soundscape-perception-measurements">Theoretical Background (of quantitative soundscape perception measurements)</a>
  <ul class="collapse">
  <li><a href="#soundscape-circumplex-projection" id="toc-soundscape-circumplex-projection" class="nav-link" data-scroll-target="#soundscape-circumplex-projection">Soundscape Circumplex &amp; Projection</a>
  <ul class="collapse">
  <li><a href="#sec-circumplex-distribution" id="toc-sec-circumplex-distribution" class="nav-link" data-scroll-target="#sec-circumplex-distribution">Circumplex Distribution</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#defining-the-spi-framework" id="toc-defining-the-spi-framework" class="nav-link" data-scroll-target="#defining-the-spi-framework">Defining the SPI Framework</a>
  <ul class="collapse">
  <li><a href="#defining-a-target" id="toc-defining-a-target" class="nav-link" data-scroll-target="#defining-a-target">Defining a Target</a></li>
  <li><a href="#distance-metric" id="toc-distance-metric" class="nav-link" data-scroll-target="#distance-metric">Distance Metric</a></li>
  <li><a href="#targets" id="toc-targets" class="nav-link" data-scroll-target="#targets">Targets</a>
  <ul class="collapse">
  <li><a href="#bespoke-targets" id="toc-bespoke-targets" class="nav-link" data-scroll-target="#bespoke-targets">Bespoke Targets</a></li>
  <li><a href="#archetypal-targets" id="toc-archetypal-targets" class="nav-link" data-scroll-target="#archetypal-targets">Archetypal Targets</a></li>
  </ul></li>
  <li><a href="#data-source" id="toc-data-source" class="nav-link" data-scroll-target="#data-source">Data Source</a></li>
  </ul></li>
  <li><a href="#applying-a-bespoke-spi" id="toc-applying-a-bespoke-spi" class="nav-link" data-scroll-target="#applying-a-bespoke-spi">Applying a Bespoke SPI</a></li>
  <li><a href="#case-study---defining-an-archetypal-spi-for-space-typologies" id="toc-case-study---defining-an-archetypal-spi-for-space-typologies" class="nav-link" data-scroll-target="#case-study---defining-an-archetypal-spi-for-space-typologies">Case Study - Defining an Archetypal SPI for space typologies</a>
  <ul class="collapse">
  <li><a href="#space-typologies" id="toc-space-typologies" class="nav-link" data-scroll-target="#space-typologies">Space Typologies</a></li>
  <li><a href="#defining-spi_type" id="toc-defining-spi_type" class="nav-link" data-scroll-target="#defining-spi_type">Defining <span class="math inline">\(SPI_{type}\)</span></a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">      

       <div class="cell-container"><div class="cell-decorator"><pre>In [1]:</pre></div><div id="cell-1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> soundscapy <span class="im">as</span> sspy</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> utils</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> rpyskewnorm <span class="im">as</span> snpy</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> circumplex <span class="im">as</span> cx</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> soundscapy.utils.parameters <span class="im">import</span> LANGUAGE_ANGLES, PAQ_NAMES, PAQ_IDS</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/_Fellowship/Papers - Drafts/J2401_JASA_SSID-Single-Index/.venv/lib/python3.11/site-packages/rpy2/robjects/numpy2ri.py:252: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.
  warnings.warn('The global conversion available with activate() '
/Users/mitch/Library/CloudStorage/OneDrive-UniversityCollegeLondon/_Fellowship/Papers - Drafts/J2401_JASA_SSID-Single-Index/.venv/lib/python3.11/site-packages/rpy2/robjects/pandas2ri.py:368: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.
  warnings.warn('The global conversion available with activate() '</code></pre>
</div>
</div></div>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The EU Green Paper on Future Noise Policy indicates that 80 million EU citizens are suffering from unacceptable environmental noise levels , according to the WHO recommendation <span class="citation" data-cites="Berglund1999Guidelines">[@Berglund1999Guidelines]</span> and the social cost of transport noise is 0.2-2% of total GDP. The publication of the EU Directive Relating to the Assessment and Management of Environmental Noise (END) <span class="citation" data-cites="EuropeanUnion2002Directive">[@EuropeanUnion2002Directive]</span> in 2002 has led to major actions across Europe, with reducing noise levels as the focus, for which billions of Euros are being spent. However, it is widely recognised that only reducing sound level is not always feasible or cost-effective, and more importantly, with only ~30% of environmental noise annoyance depending on facets of parameters such as acoustic energy <span class="citation" data-cites="Guski1997Psychological">[@Guski1997Psychological]</span>, sound level reduction will not necessarily lead to improved quality of life.</p>
<p>Soundscape creation, separate from noise control engineering, is about the relationships between human physiology, perception, the sound environment, and its social/cultural context <span class="citation" data-cites="Kang2006Urban">[@Kang2006Urban]</span>. Soundscape research represents a paradigm shift in that it combines physical, social, and psychological approaches and considers environmental sounds as a ‘resource’ rather than ‘waste’ <span class="citation" data-cites="Kang2016Soundscape">[@Kang2016Soundscape]</span> relating to perceptual constructs rather than just physical phenomena. However, the current research is still at the stage of describing and identifying the problems and tends to be fragmented and focussed on only special cases e.g.&nbsp;subjective evaluations of soundscapes for residential areas <span class="citation" data-cites="SchulteFortkamp2013Introduction">[@SchulteFortkamp2013Introduction]</span>. In the movement from noise control to soundscape creation <span class="citation" data-cites="Aletta2015Soundscape">[@Aletta2015Soundscape]</span>, a vital step is the standardisation of methods to assess soundscape quality.</p>
<!-- TODO: Should rephrase the following paragraphs -->
<p>The Decibel (dB) is the earliest and most commonly used scientific index measuring sound level. To represent the overall level of sound with a single value on one scale, as the Decibel index does, is often desirable. For this purpose, a number of different values representing sounds at various frequencies must be combined. Several frequency weighting networks have been developed since the 1930s, considering typical human responses to sound based on equal-loudness-level contours <span class="citation" data-cites="viii">[@viii]</span> and, among them, the A-weighting network, with resultant decibel values called dBA, has been commonly used in almost all the national/international regulations <span class="citation" data-cites="ix">[@ix]</span>. However, there have been numerous criticisms on its effectiveness <span class="citation" data-cites="x">[@x]</span> as the correlations between dBA and perceived sound quality (e.g.&nbsp;noise annoyance) are often low <span class="citation" data-cites="xi">[@xi]</span>.</p>
<p>Another set of indices is psychoacoustic magnitudes, including loudness, fluctuation strength or roughness, sharpness, and pitch strength, development with sound quality studies of industrial products since the 1980’s <span class="citation" data-cites="xii">[@xii]</span>. These emerged when it was conceived that acoustic emissions had further characteristics than just level <span class="citation" data-cites="ciii">[@ciii]</span>. But while psychoacoustic magnitudes have been proved to be successful for the assessment of product sound quality <span class="citation" data-cites="xiv">[@xiv]</span>, in the field of environmental acoustics, their applicability has been limited <span class="citation" data-cites="xv">[@xv]</span>, since a significant feature of environmental acoustics is that there are multiple/dynamic sound sources.</p>
<p>Attendant with the transition from a noise reduction to soundscape paradigm is an urgent need for developing appropriate indices for soundscape, rather than continuously using dBA <span class="citation" data-cites="xvi">[@xvi]</span>.</p>
<section id="the-need-for-soundscape-indices" class="level2">
<h2 class="anchored" data-anchor-id="the-need-for-soundscape-indices">The need for Soundscape Indices</h2>
<!-- From Thesis -->
<p>Soundscape studies strive to understand the perception of a sound environment, in context, including acoustic, (non-acoustic) environmental, contextual, and personal factors. These factors combine together to form a person’s soundscape perception in complex interacting ways <span class="citation" data-cites="Berglund2006Soundscape">[@Berglund2006Soundscape]</span>. Humans and soundscapes have a dynamic bidirectional relationship - while humans and their behaviour directly influence their soundscape, humans and their behaviour are in turn influenced by their soundscape <span class="citation" data-cites="Erfanian2019Psychophysiological">[@Erfanian2019Psychophysiological]</span>.</p>
<p>When applied to urban sound and specifically to noise pollution, the soundscape approach introduces three key considerations beyond traditional noise control methods:</p>
<ol type="1">
<li>considering all aspects of the environment which may influence perception, not just the sound level and spectral content;</li>
<li>an increased and integrated consideration of the varying impacts which different sound sources and sonic characteristics have on perception; and</li>
<li>a consideration of both the positive and negative dimensions of soundscape perception.</li>
</ol>
<p>This approach can enable better outcomes by identifying positive soundscapes (in line with the END’s mandate to `preserve environmental noise quality where it is good’ <span class="citation" data-cites="EuropeanUnion2002Directive">[@EuropeanUnion2002Directive]</span>), better identify specific sources of noise which impact soundscape quality and pinpoint the characteristics which may need to be decreased, and illuminate alternative methods which could be introduced to improve a soundscape where a reduction of noise is impractical <span class="citation" data-cites="Fiebig2018Does Kang2018Impact">[@Fiebig2018Does; @Kang2018Impact]</span>. These can all lead to more opportunities to truly improve a space by identifying the causes of positive soundscapes, while also potentially decreasing the costs of noise mitigation by offering more targeted techniques and alternative approaches.</p>
<p>The traditional focus on noise levels alone fails to capture the complexity of soundscape perception, which encompasses a multitude of factors beyond mere sound pressure levels. Factors such as the presence of natural or human-made sounds, their temporal patterns, and the overall contextual meaning ascribed to these sounds all contribute to the holistic perception of a soundscape. Consequently, there is a pressing need for the development of robust indices that can encapsulate this multi-dimensional nature of soundscape perception, enabling comparative evaluations and informing targeted interventions to enhance the overall quality of acoustic environments <span class="citation" data-cites="Chen2024Interventions">[@Chen2024Interventions]</span>.</p>
<!-- End Thesis -->
<p>Across both the visual and the auditory domain, research has suggested that a disconnect exists between the physical metrics used to describe urban environments and how they are perceived <span class="citation" data-cites="Kruize2019Exploring Yang2005Acoustic">[@Kruize2019Exploring; @Yang2005Acoustic]</span>. In addition, this disconnect can be extended further into how these environments influence the health and well-being of their users. To gain a better understanding of these spaces and their immpacts on people who work and live in cities, we must create assessment methods and metrics which go beyond merely characterising the physical environment and instead translate through the user’s perception <span class="citation" data-cites="Mitchell2022Predictive">[@Mitchell2022Predictive]</span>.</p>
</section>
<section id="note-on-terminology" class="level2">
<h2 class="anchored" data-anchor-id="note-on-terminology">Note on Terminology</h2>
<p>Before delving into the core discussion, it is crucial to establish a clear understanding of the terminology employed in the realm of soundscape evaluation.</p>
<!-- From Thesis -->
<p>The soundscape community is undergoing a period of increased methodological standardization in order to better coordinate and communicate the findings of the field. This process has resulted in many operational tools designed to assess and understand how sound environments are perceived and apply this to shape modern noise control engineering approaches. Important topics which have been identified throughout this process are soundscape ‘descriptors’, ‘indicators’, and ‘indices’. <span class="citation" data-cites="Aletta2016Soundscape">@Aletta2016Soundscape</span> defined soundscape descriptors as ‘measures of how people perceive the acoustic environment’ and soundscape indicators as ‘measures used to predict the value of a soundscape descriptor’. Soundscape indices can then be defined as ‘single value scales derived from either descriptors or indicators that allow for comparison across soundscapes’ <span class="citation" data-cites="Kang2019Towards">[@Kang2019Towards]</span>.</p>
<!-- End Thesis -->
<p>Soundscape indicators refer to measurable aspects or attributes of a soundscape, such as loudness, tonal characteristics, or spectral content, which can be quantified through objective measurements or signal processing techniques. In contrast, soundscape descriptors are qualitative representations of the perceived characteristics of a soundscape, often derived from listener evaluations, subjective assessments, or semantic differential scales <span class="citation" data-cites="ISO12913Part2">[@ISO12913Part2]</span>.</p>
<p>Indices, the primary focus of this article, are single numerical values that combine multiple indicators or descriptors to provide a comprehensive representation of the overall soundscape perception. These indices serve as powerful tools for quantifying and comparing soundscapes, enabling decision-makers and stakeholders to assess the impact of interventions, monitor changes over time, and prioritize areas for improvement.</p>
<p><span class="citation" data-cites="Grinfeder2022What">[@Grinfeder2022What]</span></p>
</section>
<section id="existing-soundscape-indices" class="level2">
<h2 class="anchored" data-anchor-id="existing-soundscape-indices">Existing ‘Soundscape Indices’</h2>
<p>While the field of soundscape research has witnessed substantial progress, the development of standardized indices for evaluating and comparing soundscapes across diverse contexts has been relatively limited. Existing indices can be broadly seen as arising from two domains: soundscape ecology and soundscape perception. It is worth reviewing these indices to highlight how the framework proposed here is fundamentally different in both concept and aim.</p>
<section id="soundscape-ecology" class="level3">
<h3 class="anchored" data-anchor-id="soundscape-ecology">Soundscape Ecology</h3>
<p>Within the realm of soundscape ecology, indices such as the Acoustic Diversity Index (ADI) and Frequency-dependenty Acoustic Diversity Index (FADI) <span class="citation" data-cites="Xu2023frequency">[@Xu2023frequency]</span> have been developed to quantify the diversity and complexity of acoustic signals within a given soundscape. These indices are particularly useful in ecological studies, providing insights into the richness and diversity of biophonic (natural) and anthrophonic (human-made) sound sources.</p>
<p><mark><strong><em>Add additional information on ADI, FADI, NDSI, etc.</em></strong></mark></p>
<p>However, while these indices contribute valuable insights into the ecological aspects of soundscapes, they do not directly address the perceptual dimensions that are central to the soundscape approach <span class="citation" data-cites="SchulteFortkamp2023Soundscapes">[@SchulteFortkamp2023Soundscapes]</span>. The multi-dimensional nature of soundscape perception, encompassing factors such as pleasantness, eventfulness, and familiarity, necessitates a more comprehensive and context-sensitive approach.</p>
</section>
<section id="soundscape-perception" class="level3">
<h3 class="anchored" data-anchor-id="soundscape-perception">Soundscape Perception</h3>
<p>In the domain of soundscape perception, the Green Soundscape Index (GSI) <span class="citation" data-cites="Kogan2018Green">[@Kogan2018Green]</span> has emerged as a notable attempt to quantify the perceived quality of soundscapes, particularly in urban environments. This index incorporates factors such as the presence and levels of natural sounds, human-made sounds, and their respective contributions to the overall soundscape perception.</p>
<p>The GSI is the ratio of the perceived extent of natural sounds (PNS) to the perceived extent of traffic noise (PTN):</p>
<p><span class="math display">\[
GSI = \frac{&lt;PNS&gt;}{&lt;PTN&gt;}
\]</span></p>
<p>The GSI is noted to range between 1/5 and 5, with several ranges of values given which correspond to general categories of the perceived dominance of traffic noise.</p>
<p>While GSI represents a commendable effort to bridge the gap between objective measurements and subjective perceptions, it remains limited in its ability to capture the full complexity of soundscape perception across diverse contexts. The intricate interplay between various sound sources, their temporal patterns, and the specific context in which they are experienced necessitates a more flexible and adaptable approach to index development.</p>
</section>
</section>
<section id="motivations-goals" class="level2">
<h2 class="anchored" data-anchor-id="motivations-goals">Motivations &amp; Goals</h2>
<p>The primary motivation behind the development of the Soundscape Perception Indices (SPIs) framework stems from the need to address the existing gap in quantifying and comparing soundscape quality across diverse contexts and applications. By creating a unified framework for defining these indices, the aim is to facilitate a broader and more efficient application of the soundscape approach in various domains, such as urban planning, environmental management, acoustic design, and policy development.</p>
<p>The overarching aim of this framework is to empower stakeholders, decision-makers, and researchers with the ability to create tailored indices that align with their specific objectives and design goals, while simultaneously enabling cross-comparisons and benchmarking against empirically-defined soundscape archetypes. This dual approach not only acknowledges the context-dependent nature of soundscape perception but also fosters a common language and understanding, facilitating knowledge sharing and collaborative efforts within the field.</p>
<p><em>Ranking</em> - The ability to rank soundscapes based on their quality is a key goal of the SPI framework. This ranking can be used to compare soundscapes across different contexts, identify areas for improvement, and prioritize interventions accordingly.</p>
<p><em>Standardisation</em> - The SPI framework aims to provide a standardized approach for defining and calculating soundscape indices, ensuring consistency and comparability across different applications and domains. This standardization enables the development of best practices and facilitates knowledge exchange within the field.</p>
</section>
</section>
<section id="theoretical-background-of-quantitative-soundscape-perception-measurements" class="level1">
<h1>Theoretical Background (of quantitative soundscape perception measurements)</h1>
<section id="soundscape-circumplex-projection" class="level2">
<h2 class="anchored" data-anchor-id="soundscape-circumplex-projection">Soundscape Circumplex &amp; Projection</h2>
<p>SPI is grounded in the soundscape circumplex model <span class="citation" data-cites="Axelsson2010principal Axelsson2012Swedish">[@Axelsson2010principal; @Axelsson2012Swedish]</span>, a robust theoretical foundation for understanding and representing the multi-dimensional nature of soundscape perception. The reason for grounding the SPI into the soundscape circumplex is that we have observed this model (and its corresponding PAQs) to become the most prevalent one in soundscape literature <span class="citation" data-cites="Aletta2023Adoption">[@Aletta2023Adoption]</span>. For the sake of supporting standardization, we feel that we need the SPI to align to this model.</p>
<!-- From Thesis -->
<p>Method A is built on a series of descriptors referred to as the Perceived Affective Quality (PAQ), proposed by <span class="citation" data-cites="Axelsson2010principal">[@Axelsson2010principal]</span>. These PAQs are based on the pleasantness-activity paradigm present in research on emotions and environmental psychology, in particular Russell’s circumplex model of affect <span class="citation" data-cites="Russell1980circumplex">[@Russell1980circumplex]</span>. As summarised by Axelsson: “Russell’s model identifies two dimensions related to the perceived pleasantness of environments and how activating or arousing the environment is.”</p>
<p>To move the 8-item PAQ responses into the 2-dimensional circumplex space, we use the projection method first presented in ISO 12913-3:2018. This projection method and its associated formulae were recently updated further in <span class="citation" data-cites="Aletta2024">@Aletta2024</span> to include a correction for the language in which the survey was conducted. The formulae are as follows:</p>
<p><span class="math display">\[
% \begin{align*}
P_{ISO} = \frac{1}{\lambda_{pl}} \sum_{i=1}^{8} \cos \theta_i \cdot \sigma_i \\
E_{ISO} = \frac{1}{\lambda_{pl}} \sum_{i=1}^{8} \sin \theta_i \cdot \sigma_i
% \end{align*}
\]</span></p>
<p>where $_i$ is the response to the (i)th item of the PAQ. The resulting (x) and (y) values are then used to calculate the polar angle () and the radial distance (r) as follows:</p>
<p><mark><strong><em>Add formulae for <span class="math inline">\(\theta\)</span> and r</em></strong></mark></p>
<p>Using the angles derived in <span class="citation" data-cites="Aletta2024">@Aletta2024</span>, the following table is used to convert the angles into the ISO 12913-3:2018 circumplex space:</p>
<div class="cell-container"><div class="cell-decorator"><pre>In [2]:</pre></div><div id="tbl-lang-angles" class="cell quarto-float anchored" data-execution_count="2">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-lang-angles-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Language-specific angles for projection into the ISO 12913-3:2018 circumplex space.
</figcaption>
<div aria-describedby="tbl-lang-angles-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code anchored" id="tbl-lang-angles" data-execution_count="2"><pre class="sourceCode python cell code-with-copy"><code class="sourceCode python"><span id="tbl-lang-angles-1"><a href="#tbl-lang-angles-1" aria-hidden="true" tabindex="-1"></a>tab <span class="op">=</span> pd.DataFrame.from_dict(LANGUAGE_ANGLES, orient<span class="op">=</span><span class="st">'index'</span>, columns<span class="op">=</span>PAQ_IDS)</span>
<span id="tbl-lang-angles-2"><a href="#tbl-lang-angles-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tab</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div></div>
<p>By projecting specific soundscape perception responses into this circumplex, it becomes possible to quantify their perceptual characteristics.</p>
<div class="cell-container"><div class="cell-decorator"><pre>In [3]:</pre></div><div id="cell-5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load latest ISD dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># data = sspy.isd.load_zenodo()</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load latest ISD dataset</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>isd_file <span class="op">=</span> Path(<span class="st">"ISD v1.0 Data.csv"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(isd_file, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>data, excl_data <span class="op">=</span> sspy.isd.validate(data)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.query(<span class="st">"Language != 'cmn'"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Exclude RegentsParkJapan outliers</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># excl_id = list(data.query("LocationID == 'RegentsParkJapan'").query("ISOEventful &gt; 0.72 | ISOEventful &lt; -0.5").index)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Excluded RegentsParkFields outliers</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># excl_id = excl_id + list(data.query("LocationID == 'RegentsParkFields' and ISOPleasant &lt; 0").index) # Helicopters</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>excl_id <span class="op">=</span> [<span class="dv">652</span>, <span class="dv">706</span>, <span class="dv">548</span>, <span class="dv">550</span>, <span class="dv">551</span>, <span class="dv">553</span>, <span class="dv">569</span>, <span class="dv">580</span>, <span class="dv">609</span>, <span class="dv">618</span>, <span class="dv">623</span>, <span class="dv">636</span>, <span class="dv">643</span>]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>data.drop(excl_id, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, row <span class="kw">in</span> data.iterrows():</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    lang <span class="op">=</span> row[<span class="st">'Language'</span>]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    angles <span class="op">=</span> LANGUAGE_ANGLES[lang]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    iso_pl, iso_ev <span class="op">=</span> sspy.surveys.adj_iso_pl(row[PAQ_IDS], angles, scale<span class="op">=</span><span class="dv">4</span>), sspy.surveys.adj_iso_ev(row[PAQ_IDS], angles, scale<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    data.loc[i, <span class="st">'ISOPleasant'</span>] <span class="op">=</span> iso_pl</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    data.loc[i, <span class="st">'ISOEventful'</span>] <span class="op">=</span> iso_ev</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Renaming PAQ columns.
Checking PAQ data quality.
Identified 109 samples to remove.
[6, 9, 13, 30, 32, 46, 190, 213, 229, 244, 296, 412, 413, 428, 464, 485, 655, 734, 739, 762, 766, 780, 1067, 1274, 1290, 1316, 1320, 1338, 1346, 1347, 1397, 1425, 1431, 1446, 1447, 1470, 1485, 1491, 1504, 1505, 1510, 1512, 1517, 1522, 1523, 1527, 1599, 1698, 1734, 1817, 1911, 1948, 2069, 2107, 2109, 2111, 2150, 2199, 2277, 2293, 2384, 2386, 2490, 2523, 2584, 2592, 2695, 2762, 2767, 2783, 2789, 2825, 2826, 2832, 2840, 2856, 2859, 2879, 2883, 2889, 2910, 2932, 2956, 2969, 3031, 3058, 3077, 3124, 3149, 3163, 3185, 3202, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3272, 3302, 3365, 3414, 3491, 3502, 3510, 3517, 3533, 3583]</code></pre>
</div>
</div></div>
<div class="cell-container"><div class="cell-decorator"><pre>In [4]:</pre></div><div id="cell-6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>sspy.isd.soundscapy_describe(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">ISOPleasant</th>
<th data-quarto-table-cell-role="th">ISOEventful</th>
<th data-quarto-table-cell-role="th">pleasant</th>
<th data-quarto-table-cell-role="th">eventful</th>
<th data-quarto-table-cell-role="th">vibrant</th>
<th data-quarto-table-cell-role="th">chaotic</th>
<th data-quarto-table-cell-role="th">monotonous</th>
<th data-quarto-table-cell-role="th">calm</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">CarloV</td>
<td>116</td>
<td>0.575</td>
<td>0.067</td>
<td>0.957</td>
<td>0.517</td>
<td>0.474</td>
<td>0.043</td>
<td>0.000</td>
<td>0.483</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SanMarco</td>
<td>95</td>
<td>0.284</td>
<td>0.450</td>
<td>0.811</td>
<td>0.958</td>
<td>0.768</td>
<td>0.189</td>
<td>0.000</td>
<td>0.042</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">PlazaBibRambla</td>
<td>18</td>
<td>0.492</td>
<td>0.016</td>
<td>0.944</td>
<td>0.611</td>
<td>0.556</td>
<td>0.056</td>
<td>0.000</td>
<td>0.389</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CamdenTown</td>
<td>105</td>
<td>-0.022</td>
<td>0.408</td>
<td>0.467</td>
<td>0.914</td>
<td>0.410</td>
<td>0.505</td>
<td>0.029</td>
<td>0.057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">EustonTap</td>
<td>96</td>
<td>-0.118</td>
<td>0.237</td>
<td>0.312</td>
<td>0.771</td>
<td>0.240</td>
<td>0.531</td>
<td>0.156</td>
<td>0.073</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Noorderplantsoen</td>
<td>97</td>
<td>0.559</td>
<td>0.467</td>
<td>0.969</td>
<td>0.979</td>
<td>0.948</td>
<td>0.031</td>
<td>0.000</td>
<td>0.021</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MarchmontGarden</td>
<td>104</td>
<td>0.397</td>
<td>0.069</td>
<td>0.769</td>
<td>0.587</td>
<td>0.452</td>
<td>0.135</td>
<td>0.096</td>
<td>0.317</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MonumentoGaribaldi</td>
<td>32</td>
<td>0.561</td>
<td>0.109</td>
<td>1.000</td>
<td>0.625</td>
<td>0.625</td>
<td>0.000</td>
<td>0.000</td>
<td>0.375</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TateModern</td>
<td>152</td>
<td>0.467</td>
<td>0.312</td>
<td>0.928</td>
<td>0.862</td>
<td>0.789</td>
<td>0.072</td>
<td>0.000</td>
<td>0.138</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">PancrasLock</td>
<td>93</td>
<td>0.361</td>
<td>0.177</td>
<td>0.796</td>
<td>0.731</td>
<td>0.548</td>
<td>0.183</td>
<td>0.022</td>
<td>0.247</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TorringtonSq</td>
<td>113</td>
<td>0.179</td>
<td>0.273</td>
<td>0.681</td>
<td>0.796</td>
<td>0.540</td>
<td>0.257</td>
<td>0.062</td>
<td>0.142</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkFields</td>
<td>107</td>
<td>0.709</td>
<td>0.043</td>
<td>1.000</td>
<td>0.570</td>
<td>0.570</td>
<td>0.000</td>
<td>0.000</td>
<td>0.430</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">RegentsParkJapan</td>
<td>89</td>
<td>0.783</td>
<td>0.137</td>
<td>0.989</td>
<td>0.719</td>
<td>0.708</td>
<td>0.011</td>
<td>0.000</td>
<td>0.281</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RussellSq</td>
<td>145</td>
<td>0.585</td>
<td>0.169</td>
<td>0.952</td>
<td>0.703</td>
<td>0.662</td>
<td>0.041</td>
<td>0.007</td>
<td>0.290</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsCross</td>
<td>66</td>
<td>0.454</td>
<td>0.242</td>
<td>0.909</td>
<td>0.773</td>
<td>0.712</td>
<td>0.061</td>
<td>0.030</td>
<td>0.197</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">StPaulsRow</td>
<td>72</td>
<td>0.332</td>
<td>0.200</td>
<td>0.833</td>
<td>0.750</td>
<td>0.625</td>
<td>0.125</td>
<td>0.042</td>
<td>0.208</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CampoPrincipe</td>
<td>110</td>
<td>0.523</td>
<td>-0.046</td>
<td>0.945</td>
<td>0.473</td>
<td>0.427</td>
<td>0.045</td>
<td>0.009</td>
<td>0.518</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MiradorSanNicolas</td>
<td>28</td>
<td>0.387</td>
<td>0.146</td>
<td>0.964</td>
<td>0.679</td>
<td>0.643</td>
<td>0.036</td>
<td>0.000</td>
<td>0.321</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div></div>
<section id="sec-circumplex-distribution" class="level3">
<h3 class="anchored" data-anchor-id="sec-circumplex-distribution">Circumplex Distribution</h3>
<p>The circumplex is defined by two axes: <span class="math inline">\(P_{ISO}\)</span> and <span class="math inline">\(E_{ISO}\)</span>, which are limited to the range <span class="math inline">\([-1, +1]\)</span>. Typically, data in the soundscape circumplex is treated as a combination of two independent normal distributions, one for each axis. In some applications, this approach is sufficient for capturing the distribution of soundscape perception, however the method for calculating the SPI requires a more precise approach. The independent normal distribution approach relies on three key assumptions:</p>
<ol type="1">
<li>The two axes are normally distributed.</li>
<li>The two axes are independent of each other.</li>
<li>The two axes are symmetrically distributed.</li>
</ol>
<p>While the first assumption is generally valid, the second and third assumptions are not always met in practice. In particular, the distribution of soundscape perception responses in the circumplex is often characterised by a high degree of skewness, which can lead to inaccuracies in the calculation of the SPI. Soundscape circumplex distributions are most appropriately described as a bivariate skew-normal distribution <span class="citation" data-cites="Azzalini2005">@Azzalini2005</span> which accurately reflects the relationship between the two dimensions of the circumplex and the fact that real-world perceptual distributions have been consistently observed to not be strictly symmetric.</p>
<p>The skew-normal distribution is defined by three parameters: location (<span class="math inline">\(\mu\)</span>), scale (<span class="math inline">\(\sigma\)</span>), and shape (<span class="math inline">\(\alpha\)</span>). The location parameter defines the centre of the distribution, the scale parameter defines the spread of the distribution and the shape parameter defines the skew of the distribution. The one-dimensional skew-normal distribution is defined as <span class="citation" data-cites="Azzalini1996Multivariate">@Azzalini1996Multivariate</span>:</p>
<p><span class="math display">\[
\phi(z; \alpha) = 2 \phi(z) \Phi(\alpha z) \quad \text{for} \quad z \in \mathbb{R}
\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\Phi\)</span> are the standard normal probability density function and distribution function, respectively, and <span class="math inline">\(\alpha\)</span> is a shape variable which regulates the skewness. The distribution reduces to a standard normal density when <span class="math inline">\(\alpha = 0\)</span>. The bivariate skew-normal distribution extends this concept to two dimensions, allowing for the modelling of asymmetric and skewed distributions in a two-dimensional space such as the soundscape circumplex. The multivariate skew-normal distribution including scale and location parameters is given by combining the normal density and distribution functions <span class="citation" data-cites="Azzalini1999Statistical">[@Azzalini1999Statistical]</span>:</p>
<p><span class="math display">\[
Y = 2 \phi_k (y-\xi; \Omega) \Phi\{\alpha^T\omega^{-1}(y-\xi)\}
\]</span></p>
<p>where <span class="math inline">\(\phi_k\)</span> is the <em>k</em>-dimensional normal density with location <span class="math inline">\(\xi\)</span>, shape <span class="math inline">\(\alpha\)</span>, and covariance matrix <span class="math inline">\(\Omega\)</span>. <span class="math inline">\(\Phi \{ \dot \}\)</span> is the normal distribution function and <span class="math inline">\(\alpha\)</span> is a <em>k</em>-dimensional shape vector. When <span class="math inline">\(\alpha = 0\)</span>, <span class="math inline">\(Y\)</span> reduces to the standard multivariate normal <span class="math inline">\(N_k(\xi, \Omega)\)</span> density. A circumplex distribution can therefore be parameterised with a 2x2 covariance matrix <span class="math inline">\(\Omega\)</span>, a 2x1 location vector <span class="math inline">\(\xi\)</span>, and a 2x1 shape vector <span class="math inline">\(\alpha\)</span>, written as:</p>
<p><span class="math display">\[
Y \sim SN (\xi, \Omega, \alpha)
\]</span></p>
<p>By fitting a skew-normal distribution to the soundscape perception responses, it becomes possible to accurately capture the asymmetry and skewness of the distribution, enabling a more precise calculation of the SPI. A bivariate skew-normal distribution can be summarised as a set of these three parameters. Once parameterised, the distribution can then be sampled from to generate a synthetic distribution of soundscape perception responses.</p>
<section id="direct-and-centred-parameters" class="level4">
<h4 class="anchored" data-anchor-id="direct-and-centred-parameters">Direct and Centred parameters</h4>
</section>
</section>
</section>
</section>
<section id="defining-the-spi-framework" class="level1">
<h1>Defining the SPI Framework</h1>
<p>The Soundscape Perception Indices (SPI) framework is centred around the concept of quantifying the distance between a test distribution of interest and the desired target distribution. Its goal is to determine whether a soundscape - whether it be a real-world location, a proposed design, or a hypothetical scenario - aligns with the desired perception of that soundscape. This is achieved by first defining the target distribution, which could represent what is considered to be the ‘ideal’ soundscape perception for a given context or application. The test distribution is then compared to the target distribution using a distance metric, which quantifies the deviation between the two distributions. The resulting distance value serves as the basis for calculating the SPI, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception.</p>
<p>Although it is expected that the target distribution would usually represent the ideal or goal soundscape perception, it is also possible to define target distributions that represent undesirable or suboptimal soundscape perceptions. For instance, in a soundscape mapping context, it may be beneficial to map and identify chaotic soundscapes across a city in order to better target areas for soundscape interventions. In this case, the target distribution would be set in the chaotic quadrant and a higher SPI would indicate a closer alignment with the target distribution. This flexibility allows the SPI to be applied to a wide range of contexts and applications, enabling the quantification and comparison of soundscape quality across diverse scenarios.</p>
<p>An SPI value therefore does not represent a ‘good’ or ‘bad’ soundscape, but rather a measure of how closely the perceived soundscape aligns with the desired target soundscape perception. This approach allows for the development of bespoke indices tailored to specific design goals and objectives, while also enabling cross-comparisons and benchmarking against empirically-defined soundscape archetypes.</p>
<section id="defining-a-target" class="level2">
<h2 class="anchored" data-anchor-id="defining-a-target">Defining a Target</h2>
<p>As introduced in <a href="#sec-circumplex-distribution" class="quarto-xref">Section&nbsp;2.1.1</a>, circumplex data follows a bivariate skew-normal distribution which can be parameterised with a set of direct parameters (dp). We therefore define a target distribution as a set of these parameters, which can then be used to generate a synthetic distribution of soundscape perception responses. Three example targets are given below along with their <span class="math inline">\(dp_{target}\)</span>:</p>
<div class="cell-container"><div class="cell-decorator"><pre>In [5]:</pre></div><div id="fig-targets" class="cell quarto-figure quarto-figure-center quarto-float anchored" data-execution_count="5">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="fig-targets" data-execution_count="5"><pre class="sourceCode python cell code-with-copy"><code class="sourceCode python"><span id="fig-targets-1"><a href="#fig-targets-1" aria-hidden="true" tabindex="-1"></a>target_1 <span class="op">=</span> (</span>
<span id="fig-targets-2"><a href="#fig-targets-2" aria-hidden="true" tabindex="-1"></a>  np.array([<span class="fl">0.5</span>, <span class="fl">0.7</span>]),</span>
<span id="fig-targets-3"><a href="#fig-targets-3" aria-hidden="true" tabindex="-1"></a>  np.array(</span>
<span id="fig-targets-4"><a href="#fig-targets-4" aria-hidden="true" tabindex="-1"></a>    [[<span class="fl">0.1</span>, <span class="fl">0.05</span>],</span>
<span id="fig-targets-5"><a href="#fig-targets-5" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.05</span>, <span class="fl">0.1</span>]]</span>
<span id="fig-targets-6"><a href="#fig-targets-6" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="fig-targets-7"><a href="#fig-targets-7" aria-hidden="true" tabindex="-1"></a>  np.array([<span class="dv">0</span>, <span class="op">-</span><span class="dv">5</span>])</span>
<span id="fig-targets-8"><a href="#fig-targets-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="fig-targets-9"><a href="#fig-targets-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="fig-targets-10"><a href="#fig-targets-10" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> snpy.sample_msn(</span>
<span id="fig-targets-11"><a href="#fig-targets-11" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="fig-targets-12"><a href="#fig-targets-12" aria-hidden="true" tabindex="-1"></a>  xi <span class="op">=</span> target_1[<span class="dv">0</span>],</span>
<span id="fig-targets-13"><a href="#fig-targets-13" aria-hidden="true" tabindex="-1"></a>  omega<span class="op">=</span>target_1[<span class="dv">1</span>],</span>
<span id="fig-targets-14"><a href="#fig-targets-14" aria-hidden="true" tabindex="-1"></a>  alpha<span class="op">=</span>target_1[<span class="dv">2</span>]</span>
<span id="fig-targets-15"><a href="#fig-targets-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="fig-targets-16"><a href="#fig-targets-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="fig-targets-17"><a href="#fig-targets-17" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> pd.DataFrame(y_1, columns<span class="op">=</span>[<span class="st">'ISOPleasant'</span>, <span class="st">'ISOEventful'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-targets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1
</figcaption>
</figure>
</div></div>
</section>
<section id="distance-metric" class="level2">
<h2 class="anchored" data-anchor-id="distance-metric">Distance Metric</h2>
<p>Central to the SPI framework is the concept of a distance metric, which quantifies the deviation of a given soundscape from a desired target soundscape. This distance metric serves as the basis for calculating the SPI value, with smaller distances indicating a closer alignment between the perceived soundscape and the target soundscape perception.</p>
<p>Various distance metrics could be employed, ranging from a simple Euclidean distance</p>
<p>It would be possible to define a single target point, rather than an entire target distribution and assess the test distribution’s distance from that point using an <span class="math inline">\(R^2\)</span> based on a euclidian distance. However, as noted in Mitchell 2022, it is important to also consider the spread of the distribution. As a key aspect of the sounds, the collective perception. Of a soundscape.</p>
<p><em>Discuss different options of distance metrics and approaches</em></p>
<p>Essentially, we approaching this as a problem of (dis)similarity between soundscapes. The distance metric is then proposed to assess how similar two any given soundscapes distributions are within the circumplex. Taken to the extreme, two perfectly matching distributions in the soundscape circumplex would return a 100% SPI value, while two completely dissimilar distributions would return a 0% SPI value. In practical terms, for the former, this will never be achieved in real world scenarios; for the latter, it is also difficult to estimate how low the SPI value could actually go, and it should be considered that the distance may happen in different directions within the circumplex space. For instance, if a distribution for a vibrant soundscape was taken as a reference, a compared soundscape distribution may exhibit low SPI values for being located in the calm, OR monotonous, OR chaotic regions of the model.</p>
</section>
<section id="targets" class="level2">
<h2 class="anchored" data-anchor-id="targets">Targets</h2>
<p>The SPI framework introduces two distinct types of targets: bespoke targets and archetypal targets, each serving a unique purpose in the index development process.</p>
<section id="bespoke-targets" class="level3">
<h3 class="anchored" data-anchor-id="bespoke-targets">Bespoke Targets</h3>
<p>Bespoke targets are tailor-made for specific projects, reflecting the desired soundscape perception for a particular application. These targets can be defined by stakeholders, designers, policymakers, or decision-makers based on their unique requirements, objectives, and constraints. This flexibility allows the SPI for a specific project to be tailored to the desire of the stakeholders for how that specific soundscape should function. It can also provide a consistent and quantifiable baseline for scenarios like a soundscape design contest wherein a target is specified and provided to all participants in the contest and the winning proposal is the design with the highest SPI score when assessed against that target.</p>
</section>
<section id="archetypal-targets" class="level3">
<h3 class="anchored" data-anchor-id="archetypal-targets">Archetypal Targets</h3>
<p>In contrast to bespoke targets, archetypal targets represent generalized, widely recognized soundscape archetypes which transcend specific applications or projects. These archetypes serve as reference points and enable comparisons across different domains and use cases. <strong><em>By providing a framework for these archetypes to be defined, they can be…</em></strong></p>
<p>Additionally, archetypal SPIs can be composed of multiple targets.</p>
</section>
</section>
<section id="data-source" class="level2">
<h2 class="anchored" data-anchor-id="data-source">Data Source</h2>
<p>The SPI framework is designed to accommodate a wide range of data sources, including both objective measurements and subjective evaluations. This flexibility enables the framework to be applied to diverse contexts and applications, ranging from urban soundscapes to natural environments, public spaces, and indoor settings.</p>
<div class="cell-container"><div class="cell-decorator"><pre>In [6]:</pre></div><div id="cell-10" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>sspy.isd.soundscapy_describe(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">ISOPleasant</th>
<th data-quarto-table-cell-role="th">ISOEventful</th>
<th data-quarto-table-cell-role="th">pleasant</th>
<th data-quarto-table-cell-role="th">eventful</th>
<th data-quarto-table-cell-role="th">vibrant</th>
<th data-quarto-table-cell-role="th">chaotic</th>
<th data-quarto-table-cell-role="th">monotonous</th>
<th data-quarto-table-cell-role="th">calm</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">CarloV</td>
<td>116</td>
<td>0.575</td>
<td>0.067</td>
<td>0.957</td>
<td>0.517</td>
<td>0.474</td>
<td>0.043</td>
<td>0.000</td>
<td>0.483</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">SanMarco</td>
<td>95</td>
<td>0.284</td>
<td>0.450</td>
<td>0.811</td>
<td>0.958</td>
<td>0.768</td>
<td>0.189</td>
<td>0.000</td>
<td>0.042</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">PlazaBibRambla</td>
<td>18</td>
<td>0.492</td>
<td>0.016</td>
<td>0.944</td>
<td>0.611</td>
<td>0.556</td>
<td>0.056</td>
<td>0.000</td>
<td>0.389</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">CamdenTown</td>
<td>105</td>
<td>-0.022</td>
<td>0.408</td>
<td>0.467</td>
<td>0.914</td>
<td>0.410</td>
<td>0.505</td>
<td>0.029</td>
<td>0.057</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">EustonTap</td>
<td>96</td>
<td>-0.118</td>
<td>0.237</td>
<td>0.312</td>
<td>0.771</td>
<td>0.240</td>
<td>0.531</td>
<td>0.156</td>
<td>0.073</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Noorderplantsoen</td>
<td>97</td>
<td>0.559</td>
<td>0.467</td>
<td>0.969</td>
<td>0.979</td>
<td>0.948</td>
<td>0.031</td>
<td>0.000</td>
<td>0.021</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">MarchmontGarden</td>
<td>104</td>
<td>0.397</td>
<td>0.069</td>
<td>0.769</td>
<td>0.587</td>
<td>0.452</td>
<td>0.135</td>
<td>0.096</td>
<td>0.317</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MonumentoGaribaldi</td>
<td>32</td>
<td>0.561</td>
<td>0.109</td>
<td>1.000</td>
<td>0.625</td>
<td>0.625</td>
<td>0.000</td>
<td>0.000</td>
<td>0.375</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TateModern</td>
<td>152</td>
<td>0.467</td>
<td>0.312</td>
<td>0.928</td>
<td>0.862</td>
<td>0.789</td>
<td>0.072</td>
<td>0.000</td>
<td>0.138</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">PancrasLock</td>
<td>93</td>
<td>0.361</td>
<td>0.177</td>
<td>0.796</td>
<td>0.731</td>
<td>0.548</td>
<td>0.183</td>
<td>0.022</td>
<td>0.247</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">TorringtonSq</td>
<td>113</td>
<td>0.179</td>
<td>0.273</td>
<td>0.681</td>
<td>0.796</td>
<td>0.540</td>
<td>0.257</td>
<td>0.062</td>
<td>0.142</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RegentsParkFields</td>
<td>107</td>
<td>0.709</td>
<td>0.043</td>
<td>1.000</td>
<td>0.570</td>
<td>0.570</td>
<td>0.000</td>
<td>0.000</td>
<td>0.430</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">RegentsParkJapan</td>
<td>89</td>
<td>0.783</td>
<td>0.137</td>
<td>0.989</td>
<td>0.719</td>
<td>0.708</td>
<td>0.011</td>
<td>0.000</td>
<td>0.281</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">RussellSq</td>
<td>145</td>
<td>0.585</td>
<td>0.169</td>
<td>0.952</td>
<td>0.703</td>
<td>0.662</td>
<td>0.041</td>
<td>0.007</td>
<td>0.290</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">StPaulsCross</td>
<td>66</td>
<td>0.454</td>
<td>0.242</td>
<td>0.909</td>
<td>0.773</td>
<td>0.712</td>
<td>0.061</td>
<td>0.030</td>
<td>0.197</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">StPaulsRow</td>
<td>72</td>
<td>0.332</td>
<td>0.200</td>
<td>0.833</td>
<td>0.750</td>
<td>0.625</td>
<td>0.125</td>
<td>0.042</td>
<td>0.208</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">CampoPrincipe</td>
<td>110</td>
<td>0.523</td>
<td>-0.046</td>
<td>0.945</td>
<td>0.473</td>
<td>0.427</td>
<td>0.045</td>
<td>0.009</td>
<td>0.518</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">MiradorSanNicolas</td>
<td>28</td>
<td>0.387</td>
<td>0.146</td>
<td>0.964</td>
<td>0.679</td>
<td>0.643</td>
<td>0.036</td>
<td>0.000</td>
<td>0.321</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div></div>
</section>
</section>
<section id="applying-a-bespoke-spi" class="level1">
<h1>Applying a Bespoke SPI</h1>
</section>
<section id="case-study---defining-an-archetypal-spi-for-space-typologies" class="level1">
<h1>Case Study - Defining an Archetypal SPI for space typologies</h1>
<p>To demonstrate the practical implementation of the SPI framework and provide an example of empirically-defined targets, a case study focused on defining a typology-based SPI for public spaces is presented. This case study utilizes data from the International Soundscape Database (ISD) <span class="citation" data-cites="Mitchell2021International">[@Mitchell2021International]</span>, a comprehensive collection of soundscape recordings and associated listener evaluations gathered under the SSID Protocol <span class="citation" data-cites="Mitchell2020Soundscape">[@Mitchell2020Soundscape]</span>. The SSI Protocol was specifically designed to capture the multi-dimensional nature of soundscape perception, employed a rigorous methodology for collecting and analysing data from diverse public spaces according to the standardized methods in ISO 12913-2 <span class="citation" data-cites="ISO12913Part2">[@ISO12913Part2]</span>.</p>
<section id="space-typologies" class="level2">
<h2 class="anchored" data-anchor-id="space-typologies">Space Typologies</h2>
<p>The case study focuses on defining an archetypal SPI for public spaces, with a particular emphasis on space typologies. The concept of space typologies is rooted in the idea that different types of public spaces, such as parks, squares, streets, and plazas, exhibit distinct acoustic characteristics and elicit unique perceptions from their users. By defining archetypal SPIs for these space typologies, it becomes possible to establish a standardized framework for evaluating and comparing public spaces based on their soundscape quality.</p>
<p>The ISD encompasses a diverse range of public space typologies, including urban parks, city squares, public walkways, and busy streets. These typologies serve as the basis for defining archetypal targets and calculating the corresponding SPIs.</p>
</section>
<section id="defining-spi_type" class="level2">
<h2 class="anchored" data-anchor-id="defining-spi_type">Defining <span class="math inline">\(SPI_{type}\)</span></h2>
<p>Using the soundscape circumplex model and the perceptual data from the ISD, the process of defining the <span class="math inline">\(SPI_{type}\)</span> for each space typology involves the following steps:</p>
<ol type="1">
<li>Identifying Archetypal Targets: Based on the available data … target soundscapes are defined for each space typology, representing the ‘ideal’ soundscape perception for that particular type of public space.</li>
<li>Calculated <span class="math inline">\(SPI_{type}\)</span> for each test location: Using the procedure given above, the circumplex distribution of each test location is compared against the target distribution for its respective space typology.</li>
</ol>
<p>The resulting <span class="math inline">\(SPI_{type}\)</span> values provide a quantitative measure of soundscape quality for each space typology, enabling comparisons and benchmarking across different public spaces. By comparing each test soundscape against the appropriate target for its typology, the SPI is able to account for the different contexts and purposes of the typologies. By using a consistent scoring methodology, SPI then allows these scores to be combined and considered together, as a single <span class="math inline">\(SPI_{type}\)</span> score.</p>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>The development of bespoke and archetypal context-dependent Soundscape Perception Indices (SPIs) represents a significant step towards enabling more comprehensive and effective applications of the soundscape approach. By providing a unified framework for defining these indices, the potential for quantifying and comparing soundscape quality across diverse contexts and applications is unlocked, while still ensuring that the multi-dimensional and context-driven aspects of soundscape quality are considered.</p>
<p>The proposed framework offers several key advantages. First, it acknowledges the inherent context-dependent nature of soundscape perception, allowing for the creation of indices tailored to specific use cases or design goals through the use of bespoke targets. This flexibility ensures that the resulting SPIs accurately capture the desired soundscape perception for the given application, enabling targeted interventions and optimisations.</p>
<p>Second, the inclusion of archetypal targets facilitates cross-comparisons and benchmarking, enabling a common language and understanding of soundscape quality across different domains. By calculating the distance between a given soundscape and these widely recognized archetypes, stakeholders can identify areas for improvement and prioritize interventions accordingly, aligning their efforts with collectively recognized standards of desirable or undesirable soundscapes.</p>
<p>The case study presented in this article, focusing on the development of a typology-based SPI for public spaces, demonstrates the practical applicability of the framework. By leveraging data from the International Soundscape Database (ISD) and the SSID Protocol, archetypal targets for various space typologies were defined, and the corresponding <span class="math inline">\(SPI_{type}\)</span> values were calculated. These indices provide a quantitative measure of soundscape quality for each typology, enabling comparisons and informing decision-making processes related to the management and improvement of public spaces.</p>
<p>As stated in #sec-intro …</p>
<p><span class="citation" data-cites="Kogan2018Green">[@Kogan2018Green, Fig.6]</span>, in fact displays a startlingly similar concept, showing the locations of the three categories of traffic noise dominance (‘traffic noise’, ‘balanced’, and ‘natural’) plotted in the circumplex perceptual model. It can be clearly seen in this plot that the GSI categories create their own clusters within the circumplex.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The introduction of bespoke and archetypal context-dependent Soundscape Perception Indices (SPIs) represents a significant advancement in the field of soundscape research and application. By providing a unified framework for defining these indices, a more comprehensive and efficient approach to quantifying and comparing soundscape quality across diverse contexts is enabled.</p>
<p>The proposed framework addresses the existing gap in quantifying multi-dimensional soundscape perception, facilitating a broader application of the soundscape approach in areas such as urban planning, environmental management, acoustic design, and policy development. Through the creation of bespoke indices tailored to specific design goals and the utilization of archetypal targets for benchmarking, this framework empowers stakeholders and decision-makers to make informed choices and prioritize soundscape improvements aligned with their unique objectives and constraints.</p>
<p>Furthermore, the grounding of the SPI framework in the soundscape circumplex model ensures a robust theoretical foundation, capturing the multi-dimensional nature of soundscape perception. The use of a distance metric enables quantitative assessments and comparisons, fostering a common language and understanding of soundscape quality across different domains. This shared understanding facilitates knowledge exchange, collaborative efforts, and the development of best practices within the field.</p>
<p>The case study presented in this article, focused on defining a typology-based SPI for public spaces, demonstrates the practical applicability of the framework and highlights its potential for enabling more effective and context-sensitive soundscape management strategies. By leveraging data from the International Soundscape Database (ISD) and the SSID Protocol, archetypal targets for various public space typologies were defined, and the corresponding <span class="math inline">\(SPI_{type}\)</span> values were calculated, providing a quantitative measure of soundscape quality that can inform decision-making processes and guide interventions.</p>
<p>As the SPI framework continues to be explored and refined, future research should focus on validating and expanding the range of archetypal targets, as well as investigating the potential for incorporating additional dimensions and factors that influence soundscape perception. The integration of emerging technologies, such as virtual and augmented reality, may also provide new avenues for immersive soundscape evaluation and index development.</p>
<p>Additionally, the application of the framework in diverse real-world scenarios, ranging from urban planning and environmental management to acoustic design and policy development, will provide valuable insights and contribute to the ongoing refinement and adaptation of the SPI framework. Collaboration with stakeholders, end-users, and experts from various domains will be crucial in ensuring the framework’s relevance and applicability across a wide range of contexts.</p>
<p>Furthermore, the development of standardized data collection protocols and the establishment of comprehensive soundscape databases will be essential for the widespread adoption and effective implementation of the SPI framework. Initiatives focused on promoting data sharing, interoperability, and open access to soundscape data can significantly facilitate the creation and validation of new indices, fostering a more collaborative and data-driven approach to soundscape research and management.</p>
<p>Ultimately, the introduction of bespoke and archetypal context-dependent Soundscape Perception Indices represents a significant stride towards a more holistic and nuanced understanding of our acoustic environments, paving the way for more informed decision-making and enhancing the overall quality of life in our built and natural environments. By empowering stakeholders with the ability to quantify and compare soundscape quality, new avenues are unlocked for targeted interventions, strategic planning, and the creation of soundscapes that are not only acoustically optimal but also deeply resonant with the diverse needs and perceptions of individuals and communities.</p>
</section>
     </main>
<!-- /main column -->  <script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>  </div> <!-- /content --> 
  
</body></html>